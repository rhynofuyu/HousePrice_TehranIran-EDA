{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124ac19b",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196c77c7",
   "metadata": {},
   "source": [
    "### 1.1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffca5913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV , KFold\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import Ridge , ElasticNet , Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor  , AdaBoostRegressor \n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb79c1f3",
   "metadata": {},
   "source": [
    "- Import data, check for comlumns and variables\n",
    "### 1.2. Load and Clean Data\n",
    "Load the dataset, inspect its structure, and perform initial cleaning. We drop the original 'Price' column (in Toman) and use 'Price(USD)' for our analysis, renaming it to 'Price'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b47bfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses = pd.read_csv(\"./data/housePrice.csv\")\n",
    "houses = houses.drop('Price', axis=1)\n",
    "houses = houses.rename(columns={'Price(USD)': 'Price'})\n",
    "houses.info()\n",
    "houses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e19c05b",
   "metadata": {},
   "source": [
    "- Since the Address column has some missing data in certain rows, we will drop these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8700e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses = houses.dropna(subset=['Address'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187a6235",
   "metadata": {},
   "source": [
    "- Check the header again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5632349",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302cf44e",
   "metadata": {},
   "source": [
    "- Check the correlation between variables and the price variable before converting them into categories (actually this is feature engineering xD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14524a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# houses['Price'] = np.log1p(houses['Price'])\n",
    "# houses['Area'] = np.log1p(pd.to_numeric(houses['Area'], errors='coerce'))\n",
    "houses['Area'] = pd.to_numeric(houses['Area'], errors='coerce')\n",
    "houses = houses.dropna(subset=['Area'])\n",
    "houses['Room'] = houses['Room'].astype('int64')\n",
    "houses['Area_per_Room'] = houses['Area'] / (houses['Room']+1)\n",
    "houses['Area_per_Room'] = houses['Area_per_Room'].replace([np.inf, -np.inf], np.nan)\n",
    "address_avg_price = houses.groupby('Address')['Price'].mean()\n",
    "houses['Avg_Price_by_Address'] = houses['Address'].map(address_avg_price)\n",
    "houses['Price_per_m2'] = houses['Price'] / houses['Area']\n",
    "address_avg_price_per_m2 = houses.groupby('Address')['Price_per_m2'].mean()\n",
    "# houses['Avg_Price_per_m2_by_Address'] = houses['Address'].map(address_avg_price_per_m2)\n",
    "houses = houses.drop('Price_per_m2', axis=1)\n",
    "\n",
    "# houses['Parking_Warehouse'] = (houses['Parking'] == True) & (houses['Warehouse'] == True)\n",
    "# houses['Parking_Elevator'] = (houses['Parking'] == True) & (houses['Elevator'] == True)\n",
    "# houses['Elevator_Warehouse'] = (houses['Elevator'] == True) & (houses['Warehouse'] == True)\n",
    "# houses['All_Amenities'] = (houses['Parking'] == True) & (houses['Warehouse'] == True) & (houses['Elevator'] == True)\n",
    "\n",
    "numeric_houses = houses.select_dtypes(include=[np.number, bool]) \n",
    "corr_matrix = numeric_houses.corr()\n",
    "corr_matrix[\"Price\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42405f2",
   "metadata": {},
   "source": [
    "- That said, the data is now complete. HOWEVER, we have not yet categorized the data into the two main types: Numerical and Categorical. Now, we will do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fbeed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert specified columns to categorical data type\n",
    "houses['Room'] = houses['Room'].astype('category')\n",
    "houses['Parking'] = houses['Parking'].astype('category')\n",
    "houses['Warehouse'] = houses['Warehouse'].astype('category')\n",
    "houses['Elevator'] = houses['Elevator'].astype('category')\n",
    "# Verify the changes\n",
    "print(\"Data types after conversion:\")\n",
    "print(houses.dtypes)\n",
    "houses.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f770b9",
   "metadata": {},
   "source": [
    "### 1.3. Outlier Removal\n",
    "To prevent extreme values from skewing the analysis, we remove the top and bottom 1% of properties based on price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3cb5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 1st and 99th percentiles\n",
    "lower_percentile = houses['Price'].quantile(0.01)\n",
    "upper_percentile = houses['Price'].quantile(0.99) # !!\n",
    "\n",
    "price_min = lower_percentile\n",
    "price_max = upper_percentile\n",
    "\n",
    "print(price_max, price_min)\n",
    "\n",
    "print(f\"1st percentile (1% lowest): ${lower_percentile:.2f}\")\n",
    "print(f\"99th percentile (1% highest): ${upper_percentile:.2f}\")\n",
    "\n",
    "# Remove outliers\n",
    "houses_before = len(houses)\n",
    "houses = houses[(houses['Price'] >= lower_percentile) & (houses['Price'] <= upper_percentile)]\n",
    "houses_after = len(houses)\n",
    "\n",
    "print(f\"\\nDataset size before removing outliers: {houses_before}\")\n",
    "print(f\"Dataset size after removing outliers: {houses_after}\")\n",
    "print(f\"Removed {houses_before - houses_after} outliers ({((houses_before - houses_after) / houses_before * 100):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94198a0c",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113e74f1",
   "metadata": {},
   "source": [
    "- first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092f692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f15aa6",
   "metadata": {},
   "source": [
    "- This part was already carried out in quite detail in the file `houses_price.ipynb`; you can refer to that notebook for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab0464c",
   "metadata": {},
   "source": [
    "- One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366006fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for Address column\n",
    "address_encoded = pd.get_dummies(houses['Address'], prefix='Address')\n",
    "\n",
    "# Concatenate the one-hot encoded columns with the original dataframe\n",
    "houses_encoded = pd.concat([houses, address_encoded], axis=1)\n",
    "\n",
    "# Drop the original Address column since we now have encoded versions\n",
    "houses_encoded = houses_encoded.drop('Address', axis=1)\n",
    "\n",
    "print(f\"Original dataset shape: {houses.shape}\")\n",
    "print(f\"Dataset shape after one-hot encoding: {houses_encoded.shape}\")\n",
    "print(f\"Added {address_encoded.shape[1]} new columns for Address categories\")\n",
    "\n",
    "# Display the new column names\n",
    "print(f\"\\nNew Address columns created:\")\n",
    "print(list(address_encoded.columns))\n",
    "\n",
    "# Update our main dataframe\n",
    "houses = houses_encoded\n",
    "houses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9238e9cf",
   "metadata": {},
   "source": [
    "- Transform cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080622ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = houses.drop('Price', axis=1)  \n",
    "y = houses['Price']              \n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature columns:\")\n",
    "print(list(X.columns))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,     \n",
    "    random_state=42     \n",
    ")\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "y_train_reshaped = y_train.values.reshape(-1, 1)\n",
    "y_test_reshaped = y_test.values.reshape(-1, 1)\n",
    "\n",
    "y_train_scaled = scaler_y.fit_transform(y_train_reshaped)\n",
    "\n",
    "y_test_scaled = scaler_y.transform(y_test_reshaped)\n",
    "\n",
    "y_train = pd.Series(y_train_scaled.flatten(), name=y_train.name, index=y_train.index)\n",
    "y_test = pd.Series(y_test_scaled.flatten(), name=y_test.name, index=y_test.index)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6ddeb3",
   "metadata": {},
   "source": [
    "## 3. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9523f9",
   "metadata": {},
   "source": [
    "- Split into test_set and train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bedab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"\\nTraining set:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "print(f\"\\nTesting set:\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "print(f\"\\nData split summary:\")\n",
    "print(f\"Total samples: {len(houses)}\")\n",
    "print(f\"Training samples: {len(X_train)} ({len(X_train)/len(houses)*100:.1f}%)\")\n",
    "print(f\"Testing samples: {len(X_test)} ({len(X_test)/len(houses)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae8a970",
   "metadata": {},
   "source": [
    "- try with models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e01f3f0",
   "metadata": {},
   "source": [
    "- just convert function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57102c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_min = scaler_y.data_min_[0]\n",
    "price_max = scaler_y.data_max_[0]\n",
    "def convert_scaled_to_original_price(scaled_value, price_min=None, price_max=None):\n",
    "    \"\"\"\n",
    "    Convert scaled price value back to original USD price\n",
    "    \n",
    "    Parameters:\n",
    "    scaled_value: float (0-1) - giá trị đã được MinMaxScaler\n",
    "    price_min: float - giá trị min của Price sau khi log1p \n",
    "    price_max: float - giá trị max của Price sau khi log1p \n",
    "    \n",
    "    Returns:\n",
    "    float - giá trị USD gốc\n",
    "    \"\"\"\n",
    "    \n",
    "    # Bước 1: Unscale từ [0,1] về log scale\n",
    "    log_price = scaled_value * (price_max - price_min) + price_min\n",
    "    \n",
    "    # Bước 2: Inverse log transform (expm1 là ngược lại của log1p)\n",
    "    # original_price = np.expm1(log_price)\n",
    "    original_price = log_price\n",
    "    \n",
    "    return original_price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca55ec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import pandas as pd\n",
    "\n",
    "models = {\n",
    "    'Ridge Regression': Ridge(random_state=42),\n",
    "    'Lasso Regression': Lasso(random_state=42),\n",
    "    'ElasticNet': ElasticNet(random_state=42),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'K-Neighbors': KNeighborsRegressor(),\n",
    "    'AdaBoost': AdaBoostRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "\n",
    "print(\"Running K-Fold Cross Validation (k=10) for each model...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test each model with k-fold cross validation\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTesting {model_name}...\")\n",
    "    \n",
    "    # Perform 10-fold cross validation\n",
    "    # Using neg_root_mean_squared_error (negative RMSE)\n",
    "    cv_scores = -cross_val_score(\n",
    "        model, X_train, y_train,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        cv=10,\n",
    "        n_jobs=-1  # Use all available processors\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    results[model_name] = cv_scores\n",
    "    \n",
    "    # Display statistics\n",
    "    score_stats = pd.Series(cv_scores).describe()\n",
    "    print(f\"Cross-validation RMSE scores for {model_name}:\")\n",
    "    print(score_stats)\n",
    "    print(f\"Mean RMSE: {cv_scores.mean():.6f} (+/- {cv_scores.std() * 2:.6f})\")\n",
    "    \n",
    "    # Convert to original USD\n",
    "    mean_rmse_usd = convert_scaled_to_original_price(cv_scores.mean(), price_min, price_max)\n",
    "    print(f\"Mean RMSE in original USD: ${mean_rmse_usd:,.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY OF ALL MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create summary comparison\n",
    "summary_data = []\n",
    "for model_name, scores in results.items():\n",
    "    mean_rmse = scores.mean()\n",
    "    mean_rmse_usd = convert_scaled_to_original_price(mean_rmse, price_min, price_max)\n",
    "    \n",
    "    summary_data.append({\n",
    "        'Model': model_name,\n",
    "        'Mean RMSE': mean_rmse,\n",
    "        'Mean RMSE (USD)': mean_rmse_usd,\n",
    "        'Std RMSE': scores.std(),\n",
    "        'Min RMSE': scores.min(),\n",
    "        'Max RMSE': scores.max()\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.sort_values('Mean RMSE')\n",
    "\n",
    "# Format the USD column for better display\n",
    "summary_df_display = summary_df.copy()\n",
    "summary_df_display['Mean RMSE (USD)'] = summary_df_display['Mean RMSE (USD)'].apply(lambda x: f\"${x:,.2f}\")\n",
    "\n",
    "print(summary_df_display[['Model', 'Mean RMSE', 'Mean RMSE (USD)', 'Std RMSE']].to_string(index=False))\n",
    "\n",
    "# Find the best model\n",
    "best_model_name = summary_df.iloc[0]['Model']\n",
    "best_rmse = summary_df.iloc[0]['Mean RMSE']\n",
    "best_rmse_usd = summary_df.iloc[0]['Mean RMSE (USD)']\n",
    "\n",
    "print(f\"\\nBest performing model: {best_model_name}\")\n",
    "print(f\"Best RMSE: {best_rmse:.6f}\")\n",
    "print(f\"Best RMSE in original USD: ${best_rmse_usd:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b3a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RandomForestRegressor(random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "rmse_train_usd = convert_scaled_to_original_price(rmse_train, price_min, price_max)\n",
    "rmse_test_usd = convert_scaled_to_original_price(rmse_test, price_min, price_max)\n",
    "\n",
    "print(\"Random Forest Model Performance:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training Set:\")\n",
    "print(f\"  R² Score: {r2_train:.6f}\")\n",
    "print(f\"  RMSE: {rmse_train:.6f}\")\n",
    "print(f\"  RMSE (USD): ${rmse_train_usd:,.2f}\")\n",
    "\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  R² Score: {r2_test:.6f}\")\n",
    "print(f\"  RMSE: {rmse_test:.6f}\")\n",
    "print(f\"  RMSE (USD): ${rmse_test_usd:,.2f}\")\n",
    "\n",
    "print(f\"\\nModel Comparison:\")\n",
    "print(f\"  Difference in R² (Train - Test): {r2_train - r2_test:.6f}\")\n",
    "print(f\"  Difference in RMSE (Test - Train): {rmse_test - rmse_train:.6f}\")\n",
    "\n",
    "if r2_train - r2_test > 0.1:\n",
    "    print(\"Potential overfitting detected (R² difference > 0.1)\")\n",
    "else:\n",
    "    print(\"Good generalization performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bd9930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Define parameter distributions for RandomizedSearchCV\n",
    "param_distribs = {\n",
    "    'n_estimators': randint(low=50, high=300),\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': randint(low=3, high=20),\n",
    "    'min_samples_split': randint(low=2, high=20),\n",
    "    'min_samples_leaf': randint(low=1, high=10),\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Create RandomizedSearchCV\n",
    "rnd_search = RandomizedSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_distributions=param_distribs,\n",
    "    n_iter=100,  # Number of parameter settings sampled\n",
    "    cv=5,        # 5-fold cross validation\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1    # Use all available processors\n",
    ")\n",
    "\n",
    "print(\"Starting Randomized Search CV...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the randomized search\n",
    "rnd_search.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Randomized Search completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Get the best parameters and score\n",
    "print(\"\\nBest parameters found:\")\n",
    "print(rnd_search.best_params_)\n",
    "print(f\"\\nBest cross-validation RMSE: {-rnd_search.best_score_:.6f}\")\n",
    "print(f\"Best RMSE in USD: ${convert_scaled_to_original_price(-rnd_search.best_score_, price_min, price_max):,.2f}\")\n",
    "\n",
    "# Train the best model on full training set and evaluate\n",
    "best_rf_model = rnd_search.best_estimator_\n",
    "y_train_pred_best = best_rf_model.predict(X_train)\n",
    "y_test_pred_best = best_rf_model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "r2_train_best = r2_score(y_train, y_train_pred_best)\n",
    "r2_test_best = r2_score(y_test, y_test_pred_best)\n",
    "rmse_train_best = np.sqrt(mean_squared_error(y_train, y_train_pred_best))\n",
    "rmse_test_best = np.sqrt(mean_squared_error(y_test, y_test_pred_best))\n",
    "\n",
    "print(f\"\\nOptimized Random Forest Performance:\")\n",
    "print(f\"Training R²: {r2_train_best:.6f}\")\n",
    "print(f\"Test R²: {r2_test_best:.6f}\")\n",
    "print(f\"Training RMSE: {rmse_train_best:.6f} (${convert_scaled_to_original_price(rmse_train_best, price_min, price_max):,.2f})\")\n",
    "print(f\"Test RMSE: {rmse_test_best:.6f} (${convert_scaled_to_original_price(rmse_test_best, price_min, price_max):,.2f})\")\n",
    "\n",
    "# Compare with original model\n",
    "print(f\"\\nComparison with original Random Forest:\")\n",
    "print(f\"Original Test RMSE: {rmse_test:.6f} vs Optimized: {rmse_test_best:.6f}\")\n",
    "print(f\"Improvement: {((rmse_test - rmse_test_best) / rmse_test * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f25d77",
   "metadata": {},
   "source": [
    "## 4. EDA test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d706f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(price_min)\n",
    "print(price_max)\n",
    "\n",
    "# Calculate percentage errors for the optimized Random Forest model\n",
    "y_test_original = scaler_y.inverse_transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "y_test_pred_original = scaler_y.inverse_transform(y_test_pred_best.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(\"Sample of original prices:\")\n",
    "print(y_test_original[:5])\n",
    "print(\"\\nSample of predicted prices:\")\n",
    "print(y_test_pred_original[:5])\n",
    "\n",
    "# Calculate percentage error\n",
    "percentage_errors = np.abs((y_test_pred_original - y_test_original) / y_test_original) * 100\n",
    "\n",
    "# Identify predictions with error > 20%\n",
    "high_error_mask = percentage_errors > 20\n",
    "high_error_indices = np.where(high_error_mask)[0]\n",
    "\n",
    "print(f\"Total test samples: {len(y_test)}\")\n",
    "print(f\"Predictions with error > 20%: {np.sum(high_error_mask)} ({np.sum(high_error_mask)/len(y_test)*100:.1f}%)\")\n",
    "print(f\"Mean percentage error: {percentage_errors.mean():.2f}%\")\n",
    "print(f\"Median percentage error: {np.median(percentage_errors):.2f}%\")\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Scatter plot: Actual vs Predicted prices\n",
    "ax1 = axes[0, 0]\n",
    "scatter = ax1.scatter(y_test_original, y_test_pred_original, \n",
    "                     c=percentage_errors, cmap='viridis', alpha=0.6, s=30)\n",
    "ax1.plot([y_test_original.min(), y_test_original.max()], \n",
    "         [y_test_original.min(), y_test_original.max()], 'r--', alpha=0.8)\n",
    "ax1.set_xlabel('Actual Price (USD)')\n",
    "ax1.set_ylabel('Predicted Price (USD)')\n",
    "ax1.set_title('Actual vs Predicted Prices\\n(Color = Percentage Error)')\n",
    "plt.colorbar(scatter, ax=ax1, label='Percentage Error (%)')\n",
    "\n",
    "# Highlight high error points\n",
    "high_error_actual = y_test_original[high_error_mask]\n",
    "high_error_pred = y_test_pred_original[high_error_mask]\n",
    "ax1.scatter(high_error_actual, high_error_pred, color='red', s=50, alpha=0.8, \n",
    "           edgecolors='black', linewidth=1, label=f'Error > 20% (n={len(high_error_actual)})')\n",
    "ax1.legend()\n",
    "\n",
    "# 2. Distribution of percentage errors\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(percentage_errors, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "ax2.axvline(x=20, color='red', linestyle='--', linewidth=2, label='20% threshold')\n",
    "ax2.axvline(x=percentage_errors.mean(), color='orange', linestyle='-', linewidth=2, \n",
    "           label=f'Mean: {percentage_errors.mean():.1f}%')\n",
    "ax2.set_xlabel('Percentage Error (%)')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Distribution of Percentage Errors')\n",
    "ax2.legend()\n",
    "\n",
    "# 3. Error vs Actual Price\n",
    "ax3 = axes[1, 0]\n",
    "ax3.scatter(y_test_original, percentage_errors, alpha=0.6, s=30, color='blue')\n",
    "ax3.scatter(y_test_original[high_error_mask], percentage_errors[high_error_mask], \n",
    "           color='red', s=50, alpha=0.8, edgecolors='black', linewidth=1,\n",
    "           label=f'Error > 20% (n={np.sum(high_error_mask)})')\n",
    "ax3.axhline(y=20, color='red', linestyle='--', linewidth=2, alpha=0.7)\n",
    "ax3.set_xlabel('Actual Price (USD)')\n",
    "ax3.set_ylabel('Percentage Error (%)')\n",
    "ax3.set_title('Percentage Error vs Actual Price')\n",
    "ax3.legend()\n",
    "\n",
    "# 4. Residuals plot\n",
    "ax4 = axes[1, 1]\n",
    "residuals = y_test_pred_original - y_test_original\n",
    "ax4.scatter(y_test_original, residuals, alpha=0.6, s=30, color='blue')\n",
    "ax4.scatter(y_test_original[high_error_mask], residuals[high_error_mask], \n",
    "           color='red', s=50, alpha=0.8, edgecolors='black', linewidth=1,\n",
    "           label=f'Error > 20% (n={np.sum(high_error_mask)})')\n",
    "ax4.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "ax4.set_xlabel('Actual Price (USD)')\n",
    "ax4.set_ylabel('Residuals (Predicted - Actual)')\n",
    "ax4.set_title('Residuals vs Actual Price')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show details of worst predictions\n",
    "print(f\"\\nTop 10 worst predictions (highest percentage errors):\")\n",
    "print(\"=\"*80)\n",
    "worst_indices = np.argsort(percentage_errors)[-10:][::-1]\n",
    "for i, idx in enumerate(worst_indices, 1):\n",
    "    actual = y_test_original[idx]\n",
    "    predicted = y_test_pred_original[idx]\n",
    "    error = percentage_errors[idx]\n",
    "    print(f\"{i:2d}. Actual: ${actual:8,.0f} | Predicted: ${predicted:8,.0f} | Error: {error:5.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
